{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b8aa4d-950a-4553-a129-87a9e1e02abf",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1> Akshith Rao Singam\n",
    "<h2> Week 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2043fef1-cbc3-410c-bced-eeea039cf9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4456\\3619354104.py:2: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6012a191-0234-4019-9450-601181e14bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Flatten the images to a 1D array\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1).astype(np.float32) / 255.0\n",
    "x_test_flat = x_test.reshape(x_test.shape[0], -1).astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11a0766-d87d-4a28-bb6f-2b2a419fe6bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode the labels\n",
    "y_train_one_hot = np.eye(10)[y_train].astype(np.float32)\n",
    "y_test_one_hot = np.eye(10)[y_test].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2959a8-9545-400c-be4b-3c1788da4bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define placeholders for input and output\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28 * 28])  # 28*28 is the flattened image size\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10])  # 10 is the number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ee7fe8-910a-4933-825a-e25027a899d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "W = tf.Variable(tf.zeros([28 * 28, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594ff31a-590b-492e-a3f9-330fc3758f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "y_pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# Define the loss function (cross-entropy)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(y_pred), reduction_indices=[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deebc911-6040-4ed5-9713-630e558d4387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the optimizer (e.g., Gradient Descent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30da401-ec13-40a3-947e-5c88ca4913e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define accuracy metric\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b25ec630-c769-41a1-9dd3-188f7d330fea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, Test Accuracy: 0.8917999863624573\n",
      "Step 200, Test Accuracy: 0.9053000211715698\n",
      "Step 300, Test Accuracy: 0.9079999923706055\n",
      "Step 400, Test Accuracy: 0.9126999974250793\n",
      "Step 500, Test Accuracy: 0.9126999974250793\n",
      "Step 600, Test Accuracy: 0.9132000207901001\n",
      "Step 700, Test Accuracy: 0.9150000214576721\n",
      "Step 800, Test Accuracy: 0.9136000275611877\n",
      "Step 900, Test Accuracy: 0.9175000190734863\n",
      "Step 1000, Test Accuracy: 0.9144999980926514\n",
      "Step 1100, Test Accuracy: 0.9168000221252441\n",
      "Step 1200, Test Accuracy: 0.9185000061988831\n",
      "Step 1300, Test Accuracy: 0.9172000288963318\n",
      "Step 1400, Test Accuracy: 0.920199990272522\n",
      "Step 1500, Test Accuracy: 0.9172999858856201\n",
      "Step 1600, Test Accuracy: 0.9193000197410583\n",
      "Step 1700, Test Accuracy: 0.9204999804496765\n",
      "Step 1800, Test Accuracy: 0.9217000007629395\n",
      "Step 1900, Test Accuracy: 0.9157000184059143\n",
      "Step 2000, Test Accuracy: 0.9185000061988831\n",
      "Step 2100, Test Accuracy: 0.9218000173568726\n",
      "Step 2200, Test Accuracy: 0.921999990940094\n",
      "Step 2300, Test Accuracy: 0.9207000136375427\n",
      "Step 2400, Test Accuracy: 0.9218000173568726\n",
      "Step 2500, Test Accuracy: 0.916700005531311\n",
      "Step 2600, Test Accuracy: 0.9222999811172485\n",
      "Step 2700, Test Accuracy: 0.9168999791145325\n",
      "Step 2800, Test Accuracy: 0.9199000000953674\n",
      "Step 2900, Test Accuracy: 0.9211000204086304\n",
      "Step 3000, Test Accuracy: 0.9211000204086304\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create a list to store accuracy values\n",
    "accuracy_values = []\n",
    "\n",
    "# Create a session and run the model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 100\n",
    "    total_steps = 3000\n",
    "\n",
    "    for step in range(1, total_steps + 1):\n",
    "        # Randomly select a batch of data\n",
    "        indices = np.random.choice(len(x_train_flat), batch_size, replace=False)\n",
    "        x_batch, y_batch = x_train_flat[indices], y_train_one_hot[indices]\n",
    "\n",
    "        # Train the model on the batch\n",
    "        sess.run(train_step, feed_dict={x: x_batch, y_true: y_batch})\n",
    "\n",
    "        # Print accuracy every 100 steps and store accuracy values\n",
    "        if step % 100 == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: x_test_flat, y_true: y_test_one_hot})\n",
    "            accuracy_values.append(acc)\n",
    "            print(f\"Step {step}, Test Accuracy: {acc}\")\n",
    "\n",
    "            # Break the loop if you have collected 50 data points\n",
    "            if len(accuracy_values) == 50:\n",
    "                break\n",
    "\n",
    "# Convert the accuracy values to a NumPy array\n",
    "ACC_cnn_mnist = np.array(accuracy_values)\n",
    "\n",
    "# Save the collected accuracy values as a CSV file\n",
    "np.savetxt('ACC_cnn_mnist.csv', ACC_cnn_mnist, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7556c2-4196-4f32-9644-121528757488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
